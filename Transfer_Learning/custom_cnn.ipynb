{"cells":[{"cell_type":"markdown","metadata":{"id":"J-1ZPesNm3RP"},"source":["# CNN model with custom dataset"]},{"cell_type":"markdown","metadata":{"id":"Vr0MuujAm3RS"},"source":["- Data preprocessing\n","- Defining the CNN class\n","- Training and testing the model\n","- Make inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0zb9gcUm3RT","executionInfo":{"status":"ok","timestamp":1701488606746,"user_tz":-360,"elapsed":6032,"user":{"displayName":"Anas Mohammad Ishfaqul Muktadir Osmani","userId":"00104852233923844304"}},"outputId":"d1687ac4-153e-45a8-d50e-1bef61caa35a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting patool\n","  Downloading patool-2.0.0-py2.py3-none-any.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: patool\n","Successfully installed patool-2.0.0\n"]}],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam, lr_scheduler\n","from torch.autograd import Variable\n","import torchvision\n","import pathlib\n","import glob\n","import random\n","import shutil\n","!pip install patool\n","import patoolib"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rB1IfpYYm3RU","executionInfo":{"status":"ok","timestamp":1701488383104,"user_tz":-360,"elapsed":1146,"user":{"displayName":"Anas Mohammad Ishfaqul Muktadir Osmani","userId":"00104852233923844304"}},"outputId":"69c18c59-ef1a-44ff-efa5-30c8d60df839"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}],"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","source":["patoolib.extract_archive('30by30 images.zip')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"CE5xIOWgn9e_","executionInfo":{"status":"ok","timestamp":1701488643689,"user_tz":-360,"elapsed":550,"user":{"displayName":"Anas Mohammad Ishfaqul Muktadir Osmani","userId":"00104852233923844304"}},"outputId":"50d9a005-a999-4cbf-c6ce-f23267621db6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["INFO patool: Extracting 30by30 images.zip ...\n","INFO:patool:Extracting 30by30 images.zip ...\n","INFO patool: running /usr/bin/7z x -o./Unpack_3ugs2l8r -- \"30by30 images.zip\"\n","INFO:patool:running /usr/bin/7z x -o./Unpack_3ugs2l8r -- \"30by30 images.zip\"\n","INFO patool:     with input=''\n","INFO:patool:    with input=''\n","INFO patool: ... 30by30 images.zip extracted to `30by30 images'.\n","INFO:patool:... 30by30 images.zip extracted to `30by30 images'.\n"]},{"output_type":"execute_result","data":{"text/plain":["'30by30 images'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"4Igte_e6m3RV"},"source":["#### Splitting the dataset into training and testing sets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_MiRw3pm3RV","executionInfo":{"status":"ok","timestamp":1701488659270,"user_tz":-360,"elapsed":600,"user":{"displayName":"Anas Mohammad Ishfaqul Muktadir Osmani","userId":"00104852233923844304"}},"outputId":"2455dd9b-7acb-4a9f-a14e-4a80a4e0b518"},"outputs":[{"output_type":"stream","name":"stdout","text":["classes:  ['1', '2', '3']\n","Total images:  596\n","Training:  476\n","Testing:  120\n","Total images:  588\n","Training:  470\n","Testing:  118\n","Total images:  626\n","Training:  500\n","Testing:  126\n"]}],"source":["# Extracting the dataset and creating the train and test folders\n","data_dir = pathlib.Path('30by30 images')\n","classes = os.listdir(data_dir)\n","print('classes: ',classes)\n","\n","# Creating the train and test folders\n","if not os.path.exists('./custom_cnn_dataset'):\n","    os.makedirs('./custom_cnn_dataset/train')\n","    os.makedirs('./custom_cnn_dataset/test')\n","\n","    # Creating the class folders in train and test folders\n","    for i in classes:\n","        os.makedirs('./custom_cnn_dataset/train/' + i)\n","        os.makedirs('./custom_cnn_dataset/test/' + i)\n","\n","random.seed(0)\n","# Splitting the dataset into train and test sets\n","for i in classes:\n","    src = \"./30by30 images/\" + i # Folder to copy images from\n","    allFileNames = os.listdir(src)\n","    np.random.shuffle(allFileNames)\n","    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n","                                                              [int(len(allFileNames)*0.8)])\n","    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n","    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n","    print('Total images: ', len(allFileNames))\n","    print('Training: ', len(train_FileNames))\n","    print('Testing: ', len(test_FileNames))\n","    # Copy-pasting images\n","    for name in train_FileNames:\n","        shutil.copy(name, \"./custom_cnn_dataset/train/\" + i)\n","    for name in test_FileNames:\n","        shutil.copy(name, \"./custom_cnn_dataset/test/\" + i)"]},{"cell_type":"markdown","metadata":{"id":"5ReAJUZAm3RW"},"source":["#### Data preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8aHJx2cSm3RX"},"outputs":[],"source":["transforms = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6rQm8iPm3RY"},"outputs":[],"source":["train_dir = './custom_cnn_dataset/train'\n","train_dataloader = DataLoader(\n","    torchvision.datasets.ImageFolder(train_dir, transform=transforms),\n","    batch_size=64, shuffle=True\n",")\n","\n","test_dir = './custom_cnn_dataset/test'\n","test_dataloader = DataLoader(\n","    torchvision.datasets.ImageFolder(test_dir, transform=transforms),\n","    batch_size=64, shuffle=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"GcXcY6MRm3RY"},"source":["#### CNN class defination"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7IJsD1Hm3RZ"},"outputs":[],"source":["class ConvNet(nn.Module):\n","    def __init__(self, num_classes=3):\n","        super(ConvNet, self).__init__()\n","\n","        # Input shape = (64, 3, 30, 30)\n","        # Output size after convolutional layer = (w-f+2p)/s + 1 = (30-3+2)/1 + 1 = 30\n","        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n","        #Input shape = (64, 12, 30, 30)\n","        self.bn1 = nn.BatchNorm2d(num_features=12)\n","        self.relu1 = nn.ReLU()\n","\n","        # Input shape = (64, 12, 30, 30)\n","        # Output size after max pooling = 30/2 = 15\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n","\n","        # Input shape = (64, 12, 15, 15)\n","        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n","        self.relu2 = nn.ReLU()\n","\n","        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(num_features=32)\n","        self.relu3 = nn.ReLU()\n","        #shape = (64, 32, 15, 15)\n","\n","        self.fc = nn.Linear(in_features=15*15*32, out_features=num_classes)\n","\n","    def forward(self, input):\n","        output = self.conv1(input)\n","        output = self.bn1(output)\n","        output = self.relu1(output)\n","\n","        output = self.maxpool1(output)\n","\n","        output = self.conv2(output)\n","        output = self.relu2(output)\n","\n","        output = self.conv3(output)\n","        output = self.bn3(output)\n","        output = self.relu3(output)\n","\n","        #reshaping the output to feed into the fully connected layer\n","        output = output.view(-1, 15*15*32)\n","\n","        output = self.fc(output)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CeV0lJT3m3RZ"},"outputs":[],"source":["model = ConvNet(num_classes=3).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SZQlN2cMm3RZ"},"outputs":[],"source":["# Loss and optimizer\n","optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n","loss_fn = nn.CrossEntropyLoss()\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bo4q3B21m3Ra","executionInfo":{"status":"ok","timestamp":1701488735183,"user_tz":-360,"elapsed":540,"user":{"displayName":"Anas Mohammad Ishfaqul Muktadir Osmani","userId":"00104852233923844304"}},"outputId":"766b5ca9-c073-43dc-e4fd-895b5b787115"},"outputs":[{"output_type":"stream","name":"stdout","text":["train_count:  1446\n","test_count:  364\n"]}],"source":["#train and test count\n","train_count = len(glob.glob(train_dir + '/**/*.png'))\n","test_count = len(glob.glob(test_dir + '/**/*.png'))\n","print('train_count: ', train_count)\n","print('test_count: ', test_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92L8HvUIm3Ra","executionInfo":{"status":"ok","timestamp":1701488784319,"user_tz":-360,"elapsed":18311,"user":{"displayName":"Anas Mohammad Ishfaqul Muktadir Osmani","userId":"00104852233923844304"}},"outputId":"bd86423a-c643-4cb1-dac5-4e0298591372"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 Train Loss: tensor(0.7665) Train Accuracy: 0.6583679114799447 Test Accuracy: 0.7912087912087912\n","Epoch: 1 Train Loss: tensor(0.2390) Train Accuracy: 0.9183955739972337 Test Accuracy: 0.9203296703296703\n","Epoch: 2 Train Loss: tensor(0.1362) Train Accuracy: 0.9591977869986169 Test Accuracy: 0.9423076923076923\n","Epoch: 3 Train Loss: tensor(0.0720) Train Accuracy: 0.9778699861687413 Test Accuracy: 0.9395604395604396\n","Epoch: 4 Train Loss: tensor(0.0499) Train Accuracy: 0.9840940525587828 Test Accuracy: 0.9313186813186813\n","Epoch: 5 Train Loss: tensor(0.0386) Train Accuracy: 0.991701244813278 Test Accuracy: 0.9752747252747253\n","Epoch: 6 Train Loss: tensor(0.0255) Train Accuracy: 0.9944674965421854 Test Accuracy: 0.9862637362637363\n","Epoch: 7 Train Loss: tensor(0.0231) Train Accuracy: 0.9972337482710927 Test Accuracy: 0.9807692307692307\n","Epoch: 8 Train Loss: tensor(0.0243) Train Accuracy: 0.9944674965421854 Test Accuracy: 0.9807692307692307\n","Epoch: 9 Train Loss: tensor(0.0240) Train Accuracy: 0.9944674965421854 Test Accuracy: 0.9862637362637363\n"]}],"source":["#training the model and saving best model\n","num_epochs = 10\n","best_accuracy = 0.0\n","\n","for epoch in range(num_epochs):\n","    #Evaluation and training on training dataset\n","    model.train()\n","    train_accuracy = 0.0\n","    train_loss = 0.0\n","\n","    for i, (images, labels) in enumerate(train_dataloader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.cpu().data*images.size(0)\n","        _, prediction = torch.max(outputs.data, 1)\n","\n","        train_accuracy += int(torch.sum(prediction==labels.data))\n","\n","    train_accuracy = train_accuracy/train_count\n","    train_loss = train_loss/train_count\n","\n","    #Evaluation on testing dataset\n","    model.eval()\n","    test_accuracy = 0.0\n","    for i, (images, labels) in enumerate(test_dataloader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","\n","        outputs = model(images)\n","        _, prediction = torch.max(outputs.data, 1)\n","        test_accuracy += int(torch.sum(prediction==labels.data))\n","\n","    test_accuracy = test_accuracy/test_count\n","\n","    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n","\n","    #Save the best model\n","    if test_accuracy > best_accuracy:\n","        torch.save(model.state_dict(), 'best_checkpoint.model')\n","        best_accuracy = test_accuracy\n","\n","    scheduler.step()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}