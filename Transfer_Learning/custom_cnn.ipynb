{"cells":[{"cell_type":"markdown","metadata":{"id":"J-1ZPesNm3RP"},"source":["# CNN model with custom dataset"]},{"cell_type":"markdown","metadata":{"id":"Vr0MuujAm3RS"},"source":["- Data preprocessing\n","- Defining the CNN class\n","- Training and testing the model\n","- Make inference"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"W0zb9gcUm3RT"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: patool in /usr/local/lib/python3.10/dist-packages (2.0.0)\n"]}],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchvision.transforms import transforms\n","from torch.utils.data import DataLoader\n","from torch.optim import Adam, lr_scheduler\n","from torch.autograd import Variable\n","import torchvision\n","import pathlib\n","import glob\n","import random\n","import shutil\n","!pip install patool\n","import patoolib\n","! pip install -q torchview\n","! pip install -q -U graphviz\n","import graphviz\n","from torchview import draw_graph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"rB1IfpYYm3RU"},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CE5xIOWgn9e_"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO patool: Extracting 30by30 images.zip ...\n","INFO:patool:Extracting 30by30 images.zip ...\n","INFO patool: running /usr/bin/7z x -o./Unpack_aeopalh0 -- \"30by30 images.zip\"\n","INFO:patool:running /usr/bin/7z x -o./Unpack_aeopalh0 -- \"30by30 images.zip\"\n","INFO patool:     with input=''\n","INFO:patool:    with input=''\n","INFO patool: ... 30by30 images.zip extracted to `30by30 images1' (local file exists).\n","INFO:patool:... 30by30 images.zip extracted to `30by30 images1' (local file exists).\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'30by30 images1'"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["patoolib.extract_archive('30by30 images.zip')"]},{"cell_type":"markdown","metadata":{"id":"4Igte_e6m3RV"},"source":["#### Splitting the dataset into training and testing sets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"z_MiRw3pm3RV"},"outputs":[{"name":"stdout","output_type":"stream","text":["classes:  ['1', '3', '2']\n","Total images:  596\n","Training:  476\n","Testing:  120\n","Total images:  626\n","Training:  500\n","Testing:  126\n","Total images:  588\n","Training:  470\n","Testing:  118\n"]}],"source":["# Extracting the dataset and creating the train and test folders\n","data_dir = pathlib.Path('30by30 images')\n","classes = os.listdir(data_dir)\n","print('classes: ',classes)\n","\n","# Creating the train and test folders\n","if not os.path.exists('./custom_cnn_dataset'):\n","    os.makedirs('./custom_cnn_dataset/train')\n","    os.makedirs('./custom_cnn_dataset/test')\n","\n","    # Creating the class folders in train and test folders\n","    for i in classes:\n","        os.makedirs('./custom_cnn_dataset/train/' + i)\n","        os.makedirs('./custom_cnn_dataset/test/' + i)\n","\n","random.seed(0)\n","# Splitting the dataset into train and test sets\n","for i in classes:\n","    src = \"./30by30 images/\" + i # Folder to copy images from\n","    allFileNames = os.listdir(src)\n","    np.random.shuffle(allFileNames)\n","    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n","                                                              [int(len(allFileNames)*0.8)])\n","    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n","    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n","    print('Total images: ', len(allFileNames))\n","    print('Training: ', len(train_FileNames))\n","    print('Testing: ', len(test_FileNames))\n","    # Copy-pasting images\n","    for name in train_FileNames:\n","        shutil.copy(name, \"./custom_cnn_dataset/train/\" + i)\n","    for name in test_FileNames:\n","        shutil.copy(name, \"./custom_cnn_dataset/test/\" + i)"]},{"cell_type":"markdown","metadata":{"id":"5ReAJUZAm3RW"},"source":["#### Data preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8aHJx2cSm3RX"},"outputs":[],"source":["transforms = transforms.Compose([\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5], std=[0.5])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"e6rQm8iPm3RY"},"outputs":[],"source":["train_dir = './custom_cnn_dataset/train'\n","train_dataloader = DataLoader(\n","    torchvision.datasets.ImageFolder(train_dir, transform=transforms),\n","    batch_size=64, shuffle=True\n",")\n","\n","test_dir = './custom_cnn_dataset/test'\n","test_dataloader = DataLoader(\n","    torchvision.datasets.ImageFolder(test_dir, transform=transforms),\n","    batch_size=64, shuffle=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"GcXcY6MRm3RY"},"source":["#### CNN class defination"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"O7IJsD1Hm3RZ"},"outputs":[],"source":["class ConvNet(nn.Module):\n","    def __init__(self, num_classes=3):\n","        super(ConvNet, self).__init__()\n","\n","        # Input shape = (64, 3, 30, 30)\n","        # Output size after convolutional layer = (w-f+2p)/s + 1 = (30-3+2)/1 + 1 = 30\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=12, kernel_size=3, stride=1, padding=1)\n","        #Input shape = (64, 12, 30, 30)\n","        self.bn1 = nn.BatchNorm2d(num_features=12)\n","        self.relu1 = nn.ReLU()\n","\n","        # Input shape = (64, 12, 30, 30)\n","        # Output size after max pooling = 30/2 = 15\n","        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n","\n","        # Input shape = (64, 12, 15, 15)\n","        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n","        self.relu2 = nn.ReLU()\n","\n","        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n","        self.bn3 = nn.BatchNorm2d(num_features=32)\n","        self.relu3 = nn.ReLU()\n","        #shape = (64, 32, 15, 15)\n","\n","        self.fc = nn.Linear(in_features=15*15*32, out_features=num_classes)\n","\n","    def forward(self, input):\n","        output = self.conv1(input)\n","        output = self.bn1(output)\n","        output = self.relu1(output)\n","\n","        output = self.maxpool1(output)\n","\n","        output = self.conv2(output)\n","        output = self.relu2(output)\n","\n","        output = self.conv3(output)\n","        output = self.bn3(output)\n","        output = self.relu3(output)\n","\n","        #reshaping the output to feed into the fully connected layer\n","        output = output.view(-1, 15*15*32)\n","\n","        output = self.fc(output)\n","\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CeV0lJT3m3RZ"},"outputs":[],"source":["model = ConvNet(num_classes=3).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jmhhJOxrk2vl"},"outputs":[{"ename":"RuntimeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 256\u001b[0;31m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m_module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# this seems not to be necessary so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 146\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_orig_module_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m\u003cipython-input-16-a97748b4c35d\u003e\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 28\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m_module_forward_wrapper\u001b[0;34m(mod, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# this seems not to be necessary so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 146\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_orig_module_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--\u003e 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/recorder_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m# it leads to infinite recursive call of torch_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 241\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__torch_function__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1386\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [12, 1, 3, 3], expected input[64, 3, 30, 30] to have 1 channels, but got 3 channels instead","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-18-56cb96d7dd00\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_jupyter_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mmodel_graph1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_graph1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mdraw_graph\u001b[0;34m(model, input_data, input_size, graph_name, depth, device, dtypes, mode, strict, expand_nested, graph_dir, hide_module_functions, hide_inner_tensors, roll, show_shapes, save_graph, filename, directory, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 220\u001b[0;31m     forward_prop(\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_recorder_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mmodel_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_record_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchview/torchview.py\u001b[0m in \u001b[0;36mforward_prop\u001b[0;34m(model, x, device, model_graph, mode, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown input type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 264\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;34m\"Failed to run torchgraph see error message\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         ) from e\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchgraph see error message"]}],"source":["graphviz.set_jupyter_format('png')\n","model_graph1 = draw_graph(model, input_size=(64,3,30,30))\n","model_graph1.visual_graph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"SZQlN2cMm3RZ"},"outputs":[],"source":["# Loss and optimizer\n","optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n","loss_fn = nn.CrossEntropyLoss()\n","scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Bo4q3B21m3Ra"},"outputs":[],"source":["#train and test count\n","train_count = len(glob.glob(train_dir + '/**/*.png'))\n","test_count = len(glob.glob(test_dir + '/**/*.png'))\n","print('train_count: ', train_count)\n","print('test_count: ', test_count)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"92L8HvUIm3Ra"},"outputs":[],"source":["#training the model and saving best model\n","num_epochs = 10\n","best_accuracy = 0.0\n","\n","for epoch in range(num_epochs):\n","    #Evaluation and training on training dataset\n","    model.train()\n","    train_accuracy = 0.0\n","    train_loss = 0.0\n","\n","    for i, (images, labels) in enumerate(train_dataloader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(images)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.cpu().data*images.size(0)\n","        _, prediction = torch.max(outputs.data, 1)\n","\n","        train_accuracy += int(torch.sum(prediction==labels.data))\n","\n","    train_accuracy = train_accuracy/train_count\n","    train_loss = train_loss/train_count\n","\n","    #Evaluation on testing dataset\n","    model.eval()\n","    test_accuracy = 0.0\n","    for i, (images, labels) in enumerate(test_dataloader):\n","        if torch.cuda.is_available():\n","            images = Variable(images.cuda())\n","            labels = Variable(labels.cuda())\n","\n","        outputs = model(images)\n","        _, prediction = torch.max(outputs.data, 1)\n","        test_accuracy += int(torch.sum(prediction==labels.data))\n","\n","    test_accuracy = test_accuracy/test_count\n","\n","    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n","\n","    #Save the best model\n","    if test_accuracy \u003e best_accuracy:\n","        torch.save(model.state_dict(), 'best_checkpoint.model')\n","        best_accuracy = test_accuracy\n","\n","    scheduler.step()"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}