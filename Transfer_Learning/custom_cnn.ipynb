{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN model with custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data preprocessing\n",
    "- Defining the CNN class\n",
    "- Training and testing the model\n",
    "- Make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes:  ['1', '2', '3']\n",
      "Total images:  596\n",
      "Training:  476\n",
      "Testing:  120\n",
      "Total images:  588\n",
      "Training:  470\n",
      "Testing:  118\n",
      "Total images:  626\n",
      "Training:  500\n",
      "Testing:  126\n"
     ]
    }
   ],
   "source": [
    "# Extracting the dataset and creating the train and test folders\n",
    "data_dir = pathlib.Path('30by30 images')\n",
    "classes = os.listdir(data_dir)\n",
    "print('classes: ',classes)\n",
    "\n",
    "# Creating the train and test folders\n",
    "if not os.path.exists('./custom_cnn_dataset'):\n",
    "    os.makedirs('./custom_cnn_dataset/train')\n",
    "    os.makedirs('./custom_cnn_dataset/test')\n",
    "\n",
    "    # Creating the class folders in train and test folders\n",
    "    for i in classes:\n",
    "        os.makedirs('./custom_cnn_dataset/train/' + i)\n",
    "        os.makedirs('./custom_cnn_dataset/test/' + i)\n",
    "\n",
    "random.seed(0)\n",
    "# Splitting the dataset into train and test sets\n",
    "for i in classes:\n",
    "    src = \"./30by30 images/\" + i # Folder to copy images from\n",
    "    allFileNames = os.listdir(src)\n",
    "    np.random.shuffle(allFileNames)\n",
    "    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                              [int(len(allFileNames)*0.8)])\n",
    "    train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]\n",
    "    test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]\n",
    "    print('Total images: ', len(allFileNames))\n",
    "    print('Training: ', len(train_FileNames))\n",
    "    print('Testing: ', len(test_FileNames))\n",
    "    # Copy-pasting images\n",
    "    for name in train_FileNames:\n",
    "        shutil.copy(name, \"./custom_cnn_dataset/train/\" + i)\n",
    "    for name in test_FileNames:\n",
    "        shutil.copy(name, \"./custom_cnn_dataset/test/\" + i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './custom_cnn_dataset/train'\n",
    "train_dataloader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_dir, transform=transforms),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "\n",
    "test_dir = './custom_cnn_dataset/test'\n",
    "test_dataloader = DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_dir, transform=transforms),\n",
    "    batch_size=64, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN class defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # Input shape = (64, 3, 30, 30)\n",
    "        # Output size after convolutional layer = (w-f+2p)/s + 1 = (30-3+2)/1 + 1 = 30\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        #Input shape = (64, 12, 30, 30)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Input shape = (64, 12, 30, 30)\n",
    "        # Output size after max pooling = 30/2 = 15\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Input shape = (64, 12, 15, 15)\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        #shape = (64, 32, 15, 15)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=15*15*32, out_features=num_classes)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        \n",
    "        output = self.maxpool1(output)\n",
    "        \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        \n",
    "        #reshaping the output to feed into the fully connected layer\n",
    "        output = output.view(-1, 15*15*32)\n",
    "        \n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet(num_classes=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_count:  1808\n",
      "test_count:  1219\n"
     ]
    }
   ],
   "source": [
    "#train and test count\n",
    "train_count = len(glob.glob(train_dir + '/**/*.png'))\n",
    "test_count = len(glob.glob(test_dir + '/**/*.png'))\n",
    "print('train_count: ', train_count)\n",
    "print('test_count: ', test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(0.6873) Train Accuracy: 0.7157079646017699 Test Accuracy: 0.8777686628383922\n",
      "Epoch: 1 Train Loss: tensor(0.2042) Train Accuracy: 0.9391592920353983 Test Accuracy: 0.9327317473338802\n",
      "Epoch: 2 Train Loss: tensor(0.1085) Train Accuracy: 0.9662610619469026 Test Accuracy: 0.9196062346185397\n",
      "Epoch: 3 Train Loss: tensor(0.0769) Train Accuracy: 0.9712389380530974 Test Accuracy: 0.9647251845775225\n",
      "Epoch: 4 Train Loss: tensor(0.0495) Train Accuracy: 0.9823008849557522 Test Accuracy: 0.9721082854799016\n",
      "Epoch: 5 Train Loss: tensor(0.0283) Train Accuracy: 0.9928097345132744 Test Accuracy: 0.9958982772764561\n",
      "Epoch: 6 Train Loss: tensor(0.0256) Train Accuracy: 0.9939159292035398 Test Accuracy: 0.9983593109105825\n",
      "Epoch: 7 Train Loss: tensor(0.0236) Train Accuracy: 0.9972345132743363 Test Accuracy: 0.9983593109105825\n",
      "Epoch: 8 Train Loss: tensor(0.0195) Train Accuracy: 0.9983407079646017 Test Accuracy: 0.9983593109105825\n",
      "Epoch: 9 Train Loss: tensor(0.0191) Train Accuracy: 0.9977876106194691 Test Accuracy: 0.9991796554552912\n"
     ]
    }
   ],
   "source": [
    "#training the model and saving best model\n",
    "num_epochs = 10\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.cpu().data*images.size(0)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        \n",
    "        train_accuracy += int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "    \n",
    "    #Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    test_accuracy = 0.0\n",
    "    for i, (images, labels) in enumerate(test_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        \n",
    "        outputs = model(images)\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        test_accuracy += int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "    \n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_checkpoint.model')\n",
    "        best_accuracy = test_accuracy\n",
    "        \n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vspyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
